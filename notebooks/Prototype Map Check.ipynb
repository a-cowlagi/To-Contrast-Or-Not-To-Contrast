{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acowlagi/envs/torch_py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nets.clr_nets import SupConResNet, SupCEResNet\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LinearProtoMap():\n",
    "    def __init__(self, dataloaders, net, n_cls = 10):\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.dataloaders = dataloaders\n",
    "        self.net = net\n",
    "        self.gpu = torch.cuda.is_available()\n",
    "        self.n_cls = n_cls\n",
    "        if self.gpu:\n",
    "            self.net.cuda()\n",
    "\n",
    "    def data_prototypes(self):\n",
    "        if hasattr(self.net, \"encoder_dim\"):\n",
    "            hid_dim = self.net.encoder_dim\n",
    "        else:\n",
    "            hid_dim = self.net.fc.weight.shape[1]\n",
    "\n",
    "        prototypes = torch.zeros(self.n_cls, hid_dim)\n",
    "        lab_count = torch.zeros(self.n_cls)\n",
    "        if self.gpu:\n",
    "            prototypes = prototypes.cuda()\n",
    "            lab_count = lab_count.cuda()\n",
    "\n",
    "        num_cls = self.n_cls\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for dat, labels in self.dataloaders[0]:\n",
    "                dat, task, labels = self.create_batch(dat, labels)\n",
    "                _ = self.net(dat, task)\n",
    "                rep = self.net.rep\n",
    "                prototypes.index_add_(0, labels, rep)\n",
    "                lab_count += torch.bincount(labels, minlength=num_cls)\n",
    "\n",
    "        prototypes = prototypes / lab_count.reshape(-1, 1)\n",
    "        return prototypes\n",
    "     \n",
    "    def euclid_dist(self, proto, rep, euclid = False):\n",
    "        if euclid:\n",
    "            n = rep.shape[0]\n",
    "            k = proto.shape[0]\n",
    "            rep = rep.unsqueeze(1).expand(n, k, -1)\n",
    "            proto = proto.unsqueeze(0).expand(n, k, -1)\n",
    "            logits = -((rep - proto)**2).sum(dim=2)\n",
    "        else:\n",
    "            logits = rep @ proto.T\n",
    "        return logits\n",
    "\n",
    "    def create_batch(self, dat, labels):\n",
    "        task = None\n",
    "\n",
    "        labels = labels.long()\n",
    "        batch_size = int(labels.size()[0])\n",
    "        if self.gpu:\n",
    "            dat = dat.cuda(non_blocking=True)\n",
    "            labels = labels.cuda(non_blocking=True)\n",
    "\n",
    "        return dat, task, labels\n",
    "\n",
    "    def get_prob(self, proto = True):\n",
    "        all_out = []\n",
    "        loss, acc, count = 0.0, 0.0, 0.0\n",
    "        self.net.eval()\n",
    "\n",
    "        if proto:\n",
    "            prototypes = self.data_prototypes()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for dat, labels in self.dataloaders[0]:\n",
    "                dat, task, labels = self.create_batch(dat, labels)\n",
    "                batch_size = int(labels.size()[0])\n",
    "\n",
    "                if proto:\n",
    "                    _ = self.net(dat, task)\n",
    "                    rep = self.net.rep\n",
    "                    out = self.euclid_dist(prototypes, rep)\n",
    "                else:\n",
    "                    out = self.net(dat, task)\n",
    "\n",
    "                loss += (self.criterion(out, labels).item()) * batch_size\n",
    "\n",
    "                labels = labels.cpu().numpy()\n",
    "                out = out.cpu().detach()\n",
    "                all_out.append(torch.nn.functional.softmax(out, dim=1))\n",
    "                out = out.numpy()\n",
    "\n",
    "                acc += np.sum(labels == (np.argmax(out, axis=1)))\n",
    "                count += batch_size\n",
    "\n",
    "            ret = np.array((acc/count, loss/count))\n",
    "\n",
    "        all_out = np.concatenate(all_out)\n",
    "\n",
    "        return all_out, ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypes for SupCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../SupContrast/save/SimCLR/cifar10_models/cifar10_resnet18_lr_0.05_decay_0.0001_bsz_256_temp_0.07_cosine_seed_0/model_38.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SupConResNet(feat_dim=128)\n",
    "state_dict = ckpt['model']\n",
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model.encoder = torch.nn.DataParallel(model.encoder)\n",
    "    else:\n",
    "        new_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            k = k.replace(\"module.\", \"\")\n",
    "            new_state_dict[k] = v\n",
    "        state_dict = new_state_dict\n",
    "    model = model.cuda()\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utils.data import Cifar10Dataset, Cifar100Dataset\n",
    "\n",
    "def fetch_dataset(name):\n",
    "    if name == \"cifar10\":\n",
    "        dataset = Cifar10Dataset([0,1,2,3,4,5,6,7,8,9], permute=False)\n",
    "    elif name == \"cifar100\":\n",
    "        dataset = Cifar100Dataset([i for i in range(100)], permute=False)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = fetch_dataset(\"cifar10\")\n",
    "loaders = dataset.fetch_data_loaders(256, 10, shuf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = LinearProtoMap(loaders, model)\n",
    "probs, metrics = runner.get_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51258   , 2.24490126])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"model\"][\"head.2.bias\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype for Supervised CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../SupContrast/save/SupCE/cifar10_models/cifar10_resnet18_lr_0.2_decay_0.0001_bsz_256_cosine_seed_0/model_42.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SupCEResNet(num_classes=10)\n",
    "state_dict = ckpt['model']\n",
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model.encoder = torch.nn.DataParallel(model.encoder)\n",
    "    else:\n",
    "        new_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            k = k.replace(\"module.\", \"\")\n",
    "            new_state_dict[k] = v\n",
    "        state_dict = new_state_dict\n",
    "    model = model.cuda()\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utils.data import Cifar10Dataset, Cifar100Dataset\n",
    "\n",
    "def fetch_dataset(name, tasks = None):\n",
    "    if name == \"cifar10\":\n",
    "        if (tasks == None):\n",
    "            tasks = [0,1,2,3,4,5,6,7,8,9]\n",
    "        dataset = Cifar10Dataset(tasks, permute=False)\n",
    "    elif name == \"cifar100\":\n",
    "        if (tasks == None):\n",
    "            tasks = [i for i in range(100)]\n",
    "        dataset = Cifar100Dataset(tasks, permute=False)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = fetch_dataset(\"cifar100\", [95,96,97,98,99])\n",
    "loaders = dataset.fetch_data_loaders(256, 10, shuf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.104    , 4.6391577])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = LinearProtoMap(loaders, model, n_cls= 5)\n",
    "probs, metrics = runner.get_prob()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c794b6cdbaa1d01aff18a50b90737caa3244157ea87ee77df958c2449fba11e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
